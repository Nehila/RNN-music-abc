{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install datasets","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-24T11:51:33.896921Z","iopub.execute_input":"2025-12-24T11:51:33.897665Z","iopub.status.idle":"2025-12-24T11:51:42.441277Z","shell.execute_reply.started":"2025-12-24T11:51:33.897627Z","shell.execute_reply":"2025-12-24T11:51:42.440407Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (4.4.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.20.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\nCollecting pyarrow>=21.0.0 (from datasets)\n  Downloading pyarrow-22.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.2 kB)\nRequirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.4.0)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.3)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.5)\nRequirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.28.1)\nRequirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.6.0)\nRequirement already satisfied: multiprocess<0.70.19 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.18)\nRequirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2025.10.0)\nRequirement already satisfied: huggingface-hub<2.0,>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.36.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.3)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.2)\nRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets) (4.11.0)\nRequirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets) (2025.10.5)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets) (1.0.9)\nRequirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets) (3.11)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (4.15.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (1.2.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\nRequirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1.0.0->datasets) (1.3.1)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->datasets) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->datasets) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->datasets) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->datasets) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->datasets) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->datasets) (2024.2.0)\nDownloading pyarrow-22.0.0-cp311-cp311-manylinux_2_28_x86_64.whl (47.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m39.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pyarrow\n  Attempting uninstall: pyarrow\n    Found existing installation: pyarrow 19.0.1\n    Uninstalling pyarrow-19.0.1:\n      Successfully uninstalled pyarrow-19.0.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\npylibcudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\ncudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\ncudf-polars-cu12 25.6.0 requires pylibcudf-cu12==25.6.*, but you have pylibcudf-cu12 25.2.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed pyarrow-22.0.0\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# Chargement et exploration des données","metadata":{}},{"cell_type":"code","source":"from datasets import load_dataset\nimport json, os\n\nds = load_dataset(\"sander-wood/irishman\")  # splits: train / validation\nos.makedirs(\"irishman\", exist_ok=True)\n\n# Sauvegarde au format proche de ton TP : liste d'objets\nwith open(\"irishman/train.json\", \"w\", encoding=\"utf-8\") as f:\n    json.dump(list(ds[\"train\"]), f, ensure_ascii=False)\n\nwith open(\"irishman/validation.json\", \"w\", encoding=\"utf-8\") as f:\n    json.dump(list(ds[\"validation\"]), f, ensure_ascii=False)\n\nprint(\"OK -> irishman/train.json & irishman/validation.json\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-24T11:51:44.521265Z","iopub.execute_input":"2025-12-24T11:51:44.521888Z","iopub.status.idle":"2025-12-24T11:51:59.607484Z","shell.execute_reply.started":"2025-12-24T11:51:44.521853Z","shell.execute_reply":"2025-12-24T11:51:59.606753Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3cb9e3e5942e4695b4cf7c08c90549a7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train.json:   0%|          | 0.00/80.0M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6dd60d23909e47a7b949431183261752"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"validation.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4327f0e2630a4778b286442b01a63a15"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/214122 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"183914c33a5d44d39e1c97ff8cb680a8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/2162 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a29a4656922d417cbd36bbd4ada133eb"}},"metadata":{}},{"name":"stdout","text":"OK -> irishman/train.json & irishman/validation.json\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"# Etape 1 : Data Exploration ","metadata":{}},{"cell_type":"markdown","source":"a) Caractères uniques (train) : \nOn a extrait l’ensemble des caractères présents dans toutes les partitions ABC du jeu d’entraînement (lettres, chiffres, symboles, espaces, retours à la ligne, etc.).\n\nb) Nombre de caractères uniques :\nIl y a 95 caractères uniques dans le dataset d’entraînement.\n\nc) Pourquoi utiliser des indices au lieu des caractères ? : \nParce qu’un modèle (PyTorch) ne traite que des valeurs numériques : on convertit chaque caractère en index (id) pour pouvoir l’encoder (via embedding/one-hot) et apprendre à prédire le caractère suivant.","metadata":{}},{"cell_type":"code","source":"import json\n\nwith open(\"irishman/train.json\", \"r\", encoding=\"utf-8\") as f:\n    train_data = json.load(f)\n\nwith open(\"irishman/validation.json\", \"r\", encoding=\"utf-8\") as f:\n    val_data = json.load(f)\n\nprint(\"Nb chansons train :\", len(train_data))\nprint(\"Nb chansons val   :\", len(val_data))\n\nprint(\"\\nClés disponibles dans un exemple :\", list(train_data[0].keys()))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-24T11:52:01.500914Z","iopub.execute_input":"2025-12-24T11:52:01.501757Z","iopub.status.idle":"2025-12-24T11:52:02.169976Z","shell.execute_reply.started":"2025-12-24T11:52:01.501727Z","shell.execute_reply":"2025-12-24T11:52:02.169184Z"}},"outputs":[{"name":"stdout","text":"Nb chansons train : 214122\nNb chansons val   : 2162\n\nClés disponibles dans un exemple : ['abc notation', 'control code']\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"def find_abc_key(example: dict):\n    keys = list(example.keys())\n    # priorité à une clé qui contient \"abc\" et \"notation\"\n    for k in keys:\n        lk = k.lower()\n        if \"abc\" in lk and \"notation\" in lk:\n            return k\n    # sinon une clé qui contient \"abc\"\n    for k in keys:\n        if \"abc\" in k.lower():\n            return k\n    raise ValueError(f\"Aucune clé ABC trouvée. Clés: {keys}\")\n\nabc_key = find_abc_key(train_data[0])\nprint(\"abc_key =\", abc_key)\n\nfirst_song = train_data[0][abc_key]\nprint(\"\\n--- Première chanson (texte brut) ---\\n\")\nprint(first_song)\n\nprint(\"\\n--- Aperçu lignes (structure) ---\\n\")\nfor line in first_song.splitlines()[:15]:\n    print(line)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-24T11:52:07.825556Z","iopub.execute_input":"2025-12-24T11:52:07.826095Z","iopub.status.idle":"2025-12-24T11:52:07.831805Z","shell.execute_reply.started":"2025-12-24T11:52:07.826069Z","shell.execute_reply":"2025-12-24T11:52:07.830960Z"}},"outputs":[{"name":"stdout","text":"abc_key = abc notation\n\n--- Première chanson (texte brut) ---\n\nX:1\nL:1/8\nM:4/4\nK:Emin\n|: E2 EF E2 EF | DEFG AFDF | E2 EF E2 B2 |1 efe^d e2 e2 :|2 efe^d e3 B |: e2 ef g2 fe | \n defg afdf |1 e2 ef g2 fe | efe^d e3 B :|2 g2 bg f2 af | efe^d e2 e2 ||\n\n--- Aperçu lignes (structure) ---\n\nX:1\nL:1/8\nM:4/4\nK:Emin\n|: E2 EF E2 EF | DEFG AFDF | E2 EF E2 B2 |1 efe^d e2 e2 :|2 efe^d e3 B |: e2 ef g2 fe | \n defg afdf |1 e2 ef g2 fe | efe^d e3 B :|2 g2 bg f2 af | efe^d e2 e2 ||\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"unique_chars = set()\n\nfor obj in train_data:\n    s = obj[abc_key]\n    unique_chars.update(list(s))\n\nprint(\"Nb caractères uniques (train) :\", len(unique_chars))\nprint(\"Exemple de caractères :\", sorted(list(unique_chars))[:80])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-24T11:52:09.989509Z","iopub.execute_input":"2025-12-24T11:52:09.989804Z","iopub.status.idle":"2025-12-24T11:52:10.803674Z","shell.execute_reply.started":"2025-12-24T11:52:09.989780Z","shell.execute_reply":"2025-12-24T11:52:10.803076Z"}},"outputs":[{"name":"stdout","text":"Nb caractères uniques (train) : 95\nExemple de caractères : ['\\n', ' ', '!', '\"', '#', '$', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '=', '>', '?', '@', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', '\\\\', ']', '^', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o']\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"# Etape 2 : Mapping","metadata":{}},{"cell_type":"code","source":"# Étape 2 — Mapping caractères-index\n\n# On part de unique_chars calculé à l'étape 1\n# Important : on fixe un ordre stable (tri) pour que les index soient reproductibles\nidx2char = sorted(list(unique_chars))          # index -> char\nchar2idx = {c: i for i, c in enumerate(idx2char)}  # char -> index\n\nprint(\"Taille vocabulaire :\", len(idx2char))\nprint(\"Exemple mapping char2idx :\", {c: char2idx[c] for c in idx2char[:10]})\nprint(\"Exemple mapping idx2char :\", [idx2char[i] for i in range(10)])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-24T11:52:13.020285Z","iopub.execute_input":"2025-12-24T11:52:13.020811Z","iopub.status.idle":"2025-12-24T11:52:13.026006Z","shell.execute_reply.started":"2025-12-24T11:52:13.020788Z","shell.execute_reply":"2025-12-24T11:52:13.025211Z"}},"outputs":[{"name":"stdout","text":"Taille vocabulaire : 95\nExemple mapping char2idx : {'\\n': 0, ' ': 1, '!': 2, '\"': 3, '#': 4, '$': 5, '&': 6, \"'\": 7, '(': 8, ')': 9}\nExemple mapping idx2char : ['\\n', ' ', '!', '\"', '#', '$', '&', \"'\", '(', ')']\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"\t•\ta) char2idx : dictionnaire qui associe chaque caractère à un index unique.\n\t•\tb) idx2char : liste qui permet de retrouver le caractère à partir de son index (idx2char[i]).","metadata":{}},{"cell_type":"markdown","source":"# Étape 3 : Vectorisation des chaînes","metadata":{}},{"cell_type":"code","source":"# Étape 3 — Vectorisation des chaînes\n\ndef vectorize_string(s: str, char2idx: dict):\n    return [char2idx[c] for c in s]\n\n# Test avec la première chanson du train\nfirst_song = train_data[0][abc_key]\n\nvec = vectorize_string(first_song, char2idx)\n\nprint(\"Longueur texte :\", len(first_song))\nprint(\"Longueur vect  :\", len(vec))\nprint(\"Début (indices):\", vec[:50])\nprint(\"Début (reconstruit):\", \"\".join(idx2char[i] for i in vec[:200]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-24T11:52:15.548117Z","iopub.execute_input":"2025-12-24T11:52:15.548681Z","iopub.status.idle":"2025-12-24T11:52:15.554273Z","shell.execute_reply.started":"2025-12-24T11:52:15.548653Z","shell.execute_reply":"2025-12-24T11:52:15.553450Z"}},"outputs":[{"name":"stdout","text":"Longueur texte : 183\nLongueur vect  : 183\nDébut (indices): [56, 26, 17, 0, 44, 26, 17, 15, 24, 0, 45, 26, 20, 15, 20, 0, 43, 26, 37, 77, 73, 78, 0, 92, 26, 1, 37, 18, 1, 37, 38, 1, 37, 18, 1, 37, 38, 1, 92, 1, 36, 37, 38, 39, 1, 33, 38, 36, 38, 1]\nDébut (reconstruit): X:1\nL:1/8\nM:4/4\nK:Emin\n|: E2 EF E2 EF | DEFG AFDF | E2 EF E2 B2 |1 efe^d e2 e2 :|2 efe^d e3 B |: e2 ef g2 fe | \n defg afdf |1 e2 ef g2 fe | efe^d e3 B :|2 g2 bg f2 af | efe^d e2 e2 ||\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"La vectorisation transforme chaque caractère de la partition ABC en un indice numérique selon char2idx. On obtient ainsi une séquence d’entiers exploitable par le modèle (Embedding + LSTM).","metadata":{}},{"cell_type":"markdown","source":"# *Étape 4 : Padding des séquences***","metadata":{}},{"cell_type":"code","source":"# Étape 4a — Longueur maximale des séquences (train)\nmax_len = max(len(obj[abc_key]) for obj in train_data)\nprint(\"Longueur maximale (train) :\", max_len)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-24T11:52:18.669266Z","iopub.execute_input":"2025-12-24T11:52:18.669822Z","iopub.status.idle":"2025-12-24T11:52:18.712644Z","shell.execute_reply.started":"2025-12-24T11:52:18.669779Z","shell.execute_reply":"2025-12-24T11:52:18.712061Z"}},"outputs":[{"name":"stdout","text":"Longueur maximale (train) : 2968\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# Étape 4b — Padding / Troncature\n\ndef pad_or_truncate(s: str, max_len: int, pad_char: str = \" \"):\n    if len(s) < max_len:\n        return s + pad_char * (max_len - len(s))\n    return s[:max_len]\n\n# Test sur une chanson\ns = train_data[0][abc_key]\ns2 = pad_or_truncate(s, max_len)\n\nprint(\"Avant :\", len(s))\nprint(\"Après :\", len(s2))\nprint(\"Derniers caractères (après) :\", repr(s2[-50:]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-24T11:52:20.981103Z","iopub.execute_input":"2025-12-24T11:52:20.981799Z","iopub.status.idle":"2025-12-24T11:52:20.986657Z","shell.execute_reply.started":"2025-12-24T11:52:20.981778Z","shell.execute_reply":"2025-12-24T11:52:20.985954Z"}},"outputs":[{"name":"stdout","text":"Avant : 183\nAprès : 2968\nDerniers caractères (après) : '                                                  '\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"\t•\ta) On calcule la longueur maximale pour connaître la taille cible commune.\n\t•\tb) Le padding ajoute des espaces aux séquences courtes, et la troncature coupe les séquences trop longues, afin de pouvoir créer des batches (tensors) de même dimension.","metadata":{}},{"cell_type":"markdown","source":"# Création du dataset PyTorch****","metadata":{}},{"cell_type":"markdown","source":"**Étape 1 — Tout regrouper dans une fonction “prepare_data”**","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader\n\ndef prepare_data(train_data, val_data, abc_key, char2idx, max_len, pad_char=\" \"):\n    def pad_or_truncate(s: str):\n        if len(s) < max_len:\n            return s + pad_char * (max_len - len(s))\n        return s[:max_len]\n\n    def vectorize(s: str):\n        return [char2idx[c] for c in s]\n\n    train_seqs = [torch.tensor(vectorize(pad_or_truncate(obj[abc_key])), dtype=torch.long)\n                  for obj in train_data]\n    val_seqs   = [torch.tensor(vectorize(pad_or_truncate(obj[abc_key])), dtype=torch.long)\n                  for obj in val_data]\n\n    return train_seqs, val_seqs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-24T11:52:23.807039Z","iopub.execute_input":"2025-12-24T11:52:23.807600Z","iopub.status.idle":"2025-12-24T11:52:23.812582Z","shell.execute_reply.started":"2025-12-24T11:52:23.807574Z","shell.execute_reply":"2025-12-24T11:52:23.811812Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"**Étape 2 — Classe MusicDataset + DataLoader (batch=8 pour vérifier)**","metadata":{}},{"cell_type":"code","source":"class MusicDataset(Dataset):\n    def __init__(self, sequences):\n        self.sequences = sequences  # liste de tensors [max_len]\n\n    def __len__(self):\n        return len(self.sequences)\n\n    def __getitem__(self, idx):\n        seq = self.sequences[idx]     # [L]\n        x = seq[:-1]                  # [L-1]\n        y = seq[1:]                   # [L-1] (décalée)\n        return x, y\n\n# Construire les sequences\ntrain_seqs, val_seqs = prepare_data(train_data, val_data, abc_key, char2idx, max_len)\n\ntrain_ds = MusicDataset(train_seqs)\nval_ds   = MusicDataset(val_seqs)\n\ntrain_loader_check = DataLoader(train_ds, batch_size=8, shuffle=True)\nval_loader_check   = DataLoader(val_ds, batch_size=8, shuffle=False)\n\nxb, yb = next(iter(train_loader_check))\nprint(\"x batch shape:\", xb.shape)  # [8, L-1]\nprint(\"y batch shape:\", yb.shape)  # [8, L-1]\nprint(\"Exemple x[0][:20]:\", xb[0, :20])\nprint(\"Exemple y[0][:20]:\", yb[0, :20])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-24T11:52:26.228553Z","iopub.execute_input":"2025-12-24T11:52:26.229055Z","iopub.status.idle":"2025-12-24T11:53:34.759592Z","shell.execute_reply.started":"2025-12-24T11:52:26.229029Z","shell.execute_reply":"2025-12-24T11:53:34.758915Z"}},"outputs":[{"name":"stdout","text":"x batch shape: torch.Size([8, 2967])\ny batch shape: torch.Size([8, 2967])\nExemple x[0][:20]: tensor([56, 26, 18, 17, 16, 18, 25, 16,  0, 44, 26, 17, 15, 24,  0, 45, 26, 22,\n        15, 24])\nExemple y[0][:20]: tensor([26, 18, 17, 16, 18, 25, 16,  0, 44, 26, 17, 15, 24,  0, 45, 26, 22, 15,\n        24,  0])\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"le dataset renvoie (x, y) où y est la même séquence que x mais décalée d’un caractère, pour apprendre à prédire le prochain caractère.\n","metadata":{}},{"cell_type":"markdown","source":"**2) Implémentation du modèle LSTM**","metadata":{}},{"cell_type":"code","source":"!pip -q uninstall -y tensorboard tensorboard-data-server protobuf\n!pip -q install tensorboard==2.15.2 protobuf==3.20.3","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-24T11:54:23.346731Z","iopub.execute_input":"2025-12-24T11:54:23.347135Z","iopub.status.idle":"2025-12-24T11:54:30.605292Z","shell.execute_reply.started":"2025-12-24T11:54:23.347111Z","shell.execute_reply":"2025-12-24T11:54:30.604563Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m53.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.1/162.1 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m86.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ncudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\nopentelemetry-proto 1.37.0 requires protobuf<7.0,>=5.0, but you have protobuf 3.20.3 which is incompatible.\nonnx 1.18.0 requires protobuf>=4.25.1, but you have protobuf 3.20.3 which is incompatible.\na2a-sdk 0.3.10 requires protobuf>=5.29.5, but you have protobuf 3.20.3 which is incompatible.\nray 2.51.1 requires click!=8.3.0,>=7.0, but you have click 8.3.0 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\ntensorflow-metadata 1.17.2 requires protobuf>=4.25.2; python_version >= \"3.11\", but you have protobuf 3.20.3 which is incompatible.\npydrive2 1.21.3 requires cryptography<44, but you have cryptography 46.0.3 which is incompatible.\npydrive2 1.21.3 requires pyOpenSSL<=24.2.1,>=19.1.0, but you have pyopenssl 25.3.0 which is incompatible.\nydf 0.13.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 3.20.3 which is incompatible.\ntensorflow 2.18.0 requires tensorboard<2.19,>=2.18, but you have tensorboard 2.15.2 which is incompatible.\ngrpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 3.20.3 which is incompatible.\ngcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.10.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"import torch.nn as nn\n\nclass MusicRNN(nn.Module):\n    def __init__(self, vocab_size, embedding_dim, hidden_size):\n        super().__init__()\n        self.embed = nn.Embedding(vocab_size, embedding_dim)\n        self.lstm = nn.LSTM(embedding_dim, hidden_size, batch_first=True)\n        self.fc = nn.Linear(hidden_size, vocab_size)\n\n    def forward(self, x, hidden=None):\n        # x: [B, T]\n        e = self.embed(x)                 # [B, T, E]\n        out, hidden = self.lstm(e, hidden)# [B, T, H]\n        logits = self.fc(out)             # [B, T, V]\n        return logits, hidden","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-24T11:54:35.494532Z","iopub.execute_input":"2025-12-24T11:54:35.494837Z","iopub.status.idle":"2025-12-24T11:54:35.500883Z","shell.execute_reply.started":"2025-12-24T11:54:35.494807Z","shell.execute_reply":"2025-12-24T11:54:35.499864Z"}},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"**Boucle d’entraînement (TensorBoard + Early stopping + save best)**","metadata":{}},{"cell_type":"code","source":"from torch.utils.tensorboard import SummaryWriter\nimport torch.optim as optim\nimport os\n\ndef accuracy_from_logits(logits, y):\n    # logits: [B,T,V], y: [B,T]\n    preds = logits.argmax(dim=-1)\n    return (preds == y).float().mean().item()\n\ndef train_model(model, train_ds, val_ds, num_training_iterations=3000,\n                batch_size=256, learning_rate=5e-3,\n                patience=3, log_dir=\"runs/music_rnn\", save_path=\"best_music_rnn.pt\"):\n\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model.to(device)\n\n    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n    val_loader   = DataLoader(val_ds, batch_size=batch_size, shuffle=False)\n\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n\n    writer = SummaryWriter(log_dir=log_dir)\n\n    steps_per_epoch = len(train_loader)\n    max_epochs = (num_training_iterations + steps_per_epoch - 1) // steps_per_epoch\n\n    best_val_loss = float(\"inf\")\n    bad_epochs = 0\n    global_step = 0\n\n    for epoch in range(1, max_epochs + 1):\n        # ---- Train ----\n        model.train()\n        train_loss_sum, train_acc_sum, n_train = 0.0, 0.0, 0\n\n        for xb, yb in train_loader:\n            if global_step >= num_training_iterations:\n                break\n\n            xb, yb = xb.to(device), yb.to(device)\n\n            optimizer.zero_grad()\n            logits, _ = model(xb)\n\n            # CrossEntropy: [B*T, V] vs [B*T]\n            loss = criterion(logits.reshape(-1, logits.size(-1)), yb.reshape(-1))\n            loss.backward()\n            optimizer.step()\n\n            acc = accuracy_from_logits(logits, yb)\n\n            bs = xb.size(0)\n            train_loss_sum += loss.item() * bs\n            train_acc_sum  += acc * bs\n            n_train += bs\n\n            global_step += 1\n\n        train_loss = train_loss_sum / max(1, n_train)\n        train_acc  = train_acc_sum  / max(1, n_train)\n\n        # ---- Val ----\n        model.eval()\n        val_loss_sum, val_acc_sum, n_val = 0.0, 0.0, 0\n\n        with torch.no_grad():\n            for xb, yb in val_loader:\n                xb, yb = xb.to(device), yb.to(device)\n                logits, _ = model(xb)\n                loss = criterion(logits.reshape(-1, logits.size(-1)), yb.reshape(-1))\n                acc = accuracy_from_logits(logits, yb)\n\n                bs = xb.size(0)\n                val_loss_sum += loss.item() * bs\n                val_acc_sum  += acc * bs\n                n_val += bs\n\n        val_loss = val_loss_sum / max(1, n_val)\n        val_acc  = val_acc_sum  / max(1, n_val)\n\n        # TensorBoard logs\n        writer.add_scalar(\"loss/train\", train_loss, epoch)\n        writer.add_scalar(\"loss/val\",   val_loss,   epoch)\n        writer.add_scalar(\"acc/train\",  train_acc,  epoch)\n        writer.add_scalar(\"acc/val\",    val_acc,    epoch)\n\n        print(f\"Epoch {epoch}/{max_epochs} | train_loss={train_loss:.4f} val_loss={val_loss:.4f} | train_acc={train_acc:.4f} val_acc={val_acc:.4f}\")\n\n        # Early stopping + best save\n        if val_loss < best_val_loss:\n            best_val_loss = val_loss\n            bad_epochs = 0\n            torch.save(model.state_dict(), save_path)\n        else:\n            bad_epochs += 1\n            if bad_epochs >= patience:\n                print(\"Early stopping déclenché.\")\n                break\n\n    writer.close()\n    print(\"Best model saved ->\", save_path)\n    return save_path","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-24T11:54:37.550591Z","iopub.execute_input":"2025-12-24T11:54:37.550892Z","iopub.status.idle":"2025-12-24T11:54:53.084386Z","shell.execute_reply.started":"2025-12-24T11:54:37.550866Z","shell.execute_reply":"2025-12-24T11:54:53.083554Z"}},"outputs":[{"name":"stderr","text":"2025-12-24 11:54:39.900721: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1766577280.135348      47 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1766577280.195317      47 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"vocab_size = len(idx2char)\nembedding_dim = 128\nhidden_size = 512\n\nmodel = MusicRNN(vocab_size, embedding_dim, hidden_size)\n\nbest_path = train_model(\n    model,\n    train_ds, val_ds,\n    num_training_iterations=3000,\n    batch_size=32,\n    learning_rate=5e-3,\n    patience=3,\n    save_path=\"best_music_rnn.pt\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-24T11:54:53.085448Z","iopub.execute_input":"2025-12-24T11:54:53.085970Z","iopub.status.idle":"2025-12-24T12:16:58.143620Z","shell.execute_reply.started":"2025-12-24T11:54:53.085925Z","shell.execute_reply":"2025-12-24T12:16:58.142889Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/1 | train_loss=0.1122 val_loss=0.0950 | train_acc=0.9645 val_acc=0.9692\nBest model saved -> best_music_rnn.pt\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"import torch\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nmodel = MusicRNN(vocab_size=len(idx2char), embedding_dim=embedding_dim, hidden_size=hidden_size).to(device)\nmodel.load_state_dict(torch.load(\"best_music_rnn.pt\", map_location=device))\nmodel.eval()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-24T12:43:28.345315Z","iopub.execute_input":"2025-12-24T12:43:28.346106Z","iopub.status.idle":"2025-12-24T12:43:28.373073Z","shell.execute_reply.started":"2025-12-24T12:43:28.346079Z","shell.execute_reply":"2025-12-24T12:43:28.372482Z"}},"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"MusicRNN(\n  (embed): Embedding(95, 128)\n  (lstm): LSTM(128, 512, batch_first=True)\n  (fc): Linear(in_features=512, out_features=95, bias=True)\n)"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"import torch.nn.functional as F\n\ndef generate_music(model, start_seq, char2idx, idx2char, length=200, temperature=1.0):\n    device = next(model.parameters()).device\n    model.eval()\n\n    # vectoriser la séquence de départ\n    start_ids = [char2idx[c] for c in start_seq]\n    generated = start_ids[:]  # liste d'indices\n\n    hidden = None\n\n    with torch.no_grad():\n        # passer toute la seed pour initialiser l'état caché\n        x = torch.tensor([start_ids], dtype=torch.long, device=device)  # [1, T]\n        _, hidden = model(x, hidden)\n\n        last_id = start_ids[-1]\n\n        for _ in range(length):\n            inp = torch.tensor([[last_id]], dtype=torch.long, device=device)  # [1,1]\n            logits, hidden = model(inp, hidden)  # logits: [1,1,V]\n            logits = logits[0, 0]  # [V]\n\n            # temperature + proba\n            logits = logits / max(temperature, 1e-6)\n            probs = F.softmax(logits, dim=-1)\n\n            # échantillonnage\n            next_id = torch.multinomial(probs, num_samples=1).item()\n\n            generated.append(next_id)\n            last_id = next_id\n\n    return \"\".join(idx2char[i] for i in generated)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-24T12:43:50.752439Z","iopub.execute_input":"2025-12-24T12:43:50.752919Z","iopub.status.idle":"2025-12-24T12:43:50.759077Z","shell.execute_reply.started":"2025-12-24T12:43:50.752895Z","shell.execute_reply":"2025-12-24T12:43:50.758338Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"seed = \"X:1\\nL:1/8\\nM:4/4\\nK:Em\\n\"\ngenerated_abc = generate_music(model, seed, char2idx, idx2char, length=200, temperature=1.0)\n\nprint(\"----- Generated ABC -----\")\nprint(generated_abc)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-24T12:44:02.307956Z","iopub.execute_input":"2025-12-24T12:44:02.308245Z","iopub.status.idle":"2025-12-24T12:44:02.751287Z","shell.execute_reply.started":"2025-12-24T12:44:02.308222Z","shell.execute_reply":"2025-12-24T12:44:02.750593Z"}},"outputs":[{"name":"stdout","text":"----- Generated ABC -----\nX:1\nL:1/8\nM:4/4\nK:Em\n E2 BE G/A/B B2 | A2 A2 G2 E>G | E2 E>D E2 (E/F/E/D/) | E2 E G3 G3 G | \n B2 B>c B>A G2 | E4 E4 | F4 G3 F | E/E/E/E/ G>E E4 ||                                                                           \n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}